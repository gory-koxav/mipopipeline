# cctv_event_detector/repository/state_repository.py

import redis
import json
import time
import numpy as np
from typing import List, Dict, Any, Tuple
import atexit  # [í•µì‹¬ ì¶”ê°€] ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ ì‹¤í–‰í•  í•¨ìˆ˜ë¥¼ ë“±ë¡í•˜ê¸° ìœ„í•´ ì„í¬íŠ¸í•©ë‹ˆë‹¤.

from config import IMAGE_DATA_DIR, REDIS_HOST, REDIS_PORT, REDIS_DB
from cctv_event_detector.core.models import CapturedImage

# Redis ì—°ê²° í’€ì„ ìƒì„±í•©ë‹ˆë‹¤.
pool = redis.ConnectionPool(
    host=REDIS_HOST,
    port=REDIS_PORT,
    db=REDIS_DB,
    decode_responses=False,
    health_check_interval=30
)

# [í•µì‹¬ ì¶”ê°€] ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ Redis ì—°ê²° í’€ì„ ë‹«ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
def disconnect_redis_pool():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ Redis ì—°ê²° í’€ì˜ ëª¨ë“  ì—°ê²°ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."""
    print("ğŸ‘‹ Shutting down... Disconnecting all Redis connections from the pool.")
    pool.disconnect()

# [í•µì‹¬ ì¶”ê°€] ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë  ë•Œ disconnect_redis_pool í•¨ìˆ˜ê°€ ìë™ìœ¼ë¡œ í˜¸ì¶œë˜ë„ë¡ ë“±ë¡í•©ë‹ˆë‹¤.
atexit.register(disconnect_redis_pool)


class NumpyEncoder(json.JSONEncoder):
    """ Numpy íƒ€ì…ì„ íŒŒì´ì¬ ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ JSONìœ¼ë¡œ ì§ë ¬í™”í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤. """
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        else:
            return super(NumpyEncoder, self).default(obj)

class StateRepository:
    """
    CCTV ì´ë²¤íŠ¸ ë°ì´í„°ì˜ ìƒíƒœë¥¼ Redisì— ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ëŠ” ì±…ì„ì„ ê°€ì§‘ë‹ˆë‹¤.
    """
    def __init__(self):
        """
        StateRepositoryë¥¼ ì´ˆê¸°í™”í•˜ê³  Redis ì„œë²„ì— ì—°ê²°í•©ë‹ˆë‹¤.
        """
        try:
            # ê³µìœ ëœ ì—°ê²° í’€ì„ ì‚¬ìš©í•˜ê³ , ì‹œê°„ ì´ˆê³¼ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
            self.redis_client = redis.Redis(
                connection_pool=pool,
                socket_connect_timeout=5,
                socket_timeout=5
            )
            self.redis_client.ping()
            print(f"âœ… Redis client connected successfully using connection pool to {REDIS_HOST}:{REDIS_PORT}")
        except redis.exceptions.TimeoutError as e:
            print(f"âŒ Redis connection timed out: {e}")
            raise
        except redis.exceptions.ConnectionError as e:
            print(f"âŒ Failed to connect to Redis: {e}")
            raise

    def _compress_mask(self, mask: np.ndarray) -> bytes:
        return np.packbits(mask).tobytes()

    def _prepare_data_for_storage(
        self,
        inference_result: Dict[str, Any],
        batch_id: str,
        image_id: str
    ) -> Tuple[Dict[str, Any], List[Tuple[str, bytes]]]:
        result_copy = dict(inference_result)
        masks_to_store = []
        mask_types_to_process = {
            "boundary_masks": ("boundary", "segmentation_mask"),
            "pinjig_masks": ("pinjig", "segmentation"),
        }
        for key_in_result, (type_name, mask_field) in mask_types_to_process.items():
            if key_in_result in result_copy:
                original_masks = list(result_copy[key_in_result])
                for i, mask_data in enumerate(original_masks):
                    if mask_field in mask_data and isinstance(mask_data[mask_field], np.ndarray):
                        mask_array = mask_data.pop(mask_field)
                        compressed_mask = self._compress_mask(mask_array)
                        mask_key = f"mask:{batch_id}:{image_id}:{type_name}:{i}"
                        masks_to_store.append((mask_key, compressed_mask))
                        mask_data[mask_field] = mask_key
        return result_copy, masks_to_store

    def _get_inference_summary(self, result: Dict[str, Any]) -> str:
        summary_lines = []
        for key, value in result.items():
            if isinstance(value, list):
                summary_lines.append(f"      - {key}: {len(value)} items")
            elif isinstance(value, dict):
                summary_lines.append(f"      - {key}: {len(value.keys())} keys")
            else:
                summary_lines.append(f"      - {key}: (type: {type(value).__name__})")
        return "\n".join(summary_lines)
        
    def save_batch_results(
        self, 
        captured_images: List[CapturedImage], 
        inference_results: Dict[str, Any], 
        redis_channel: str
    ):
        if not captured_images:
            print("âš ï¸ ê²½ê³ : ì €ì¥í•  captured_images ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        batch_id = time.strftime('%Y%m%d-%H%M%S')
        batch_set_key = f"batch:{batch_id}"
        batch_result_keys = []
        processed_count = 0

        print(f"\n--- ğŸ•µï¸  Redis ì €ì¥ ì „ ë°ì´í„° ìƒì„¸ ë””ë²„ê¹… ì‹œì‘ (Batch ID: {batch_id}) ---")
        print(f"   - ì´ {len(captured_images)}ê°œì˜ ìº¡ì²˜ ë°ì´í„°ì™€ {len(inference_results)}ê°œì˜ ì¶”ë¡  ê²°ê³¼ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.\n")

        try:
            with self.redis_client.pipeline() as pipe:
                for i, capture in enumerate(captured_images):
                    image_id = capture.image_id
                    
                    print(f"-[{i+1:02d}/{len(captured_images)}] ğŸ“„ ID: {image_id}")
                    
                    if hasattr(capture, 'image_data') and capture.image_data is not None:
                        img_size_mb = capture.image_data.nbytes / (1024 * 1024)
                        print(f"    [CAPTURE] Status: âœ… Image Present | Size: {img_size_mb:.2f} MB | Time: {capture.captured_at}")
                    else:
                        print(f"    [CAPTURE] Status: âŒ Image Missing")
                    
                    inference_result = inference_results.get(image_id)
                    if inference_result:
                        print(f"    [INFERENCE] Status: âœ… Found")
                        summary = self._get_inference_summary(inference_result)
                        print(summary)
                    else:
                        print(f"    [INFERENCE] Status: âŒ Not Found")
                    print("-" * 60)

                    main_key = f"result:{batch_id}:{image_id}"
                    batch_result_keys.append(main_key)
                    
                    main_data_payload = {
                        "image_id": image_id,
                        "camera_name": capture.camera_name,
                        "captured_at": capture.captured_at.isoformat(),
                        "image_path": f"{IMAGE_DATA_DIR}/{capture.camera_name}/{image_id.split('_')[-1]}.png",
                    }

                    if inference_result:
                        prepared_data, masks_to_store = self._prepare_data_for_storage(
                            inference_result, batch_id, image_id
                        )
                        main_data_payload["inference_data"] = json.dumps(prepared_data, cls=NumpyEncoder)
                        
                        for mask_key, compressed_mask in masks_to_store:
                            pipe.set(mask_key, compressed_mask)
                    else:
                        error_payload = {
                            "status": "error",
                            "message": "AI inference result not found or failed."
                        }
                        main_data_payload["inference_data"] = json.dumps(error_payload)

                    pipe.hset(main_key, mapping=main_data_payload)
                    processed_count += 1
                
                print("\n--- âœ… ë””ë²„ê¹… ì¢…ë£Œ. Redis íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ---")

                if batch_result_keys:
                    pipe.sadd(batch_set_key, *batch_result_keys)
                    
                message_payload = json.dumps({"batch_id": batch_id, "status": "completed", "processed_count": processed_count})
                pipe.publish(redis_channel, message_payload)
                
                pipe.execute()
                
                print(f"âœ… {processed_count}ê°œ ì¹´ë©”ë¼ ìƒíƒœ ì €ì¥ ì™„ë£Œ. '{redis_channel}' ì±„ë„ì— ì•Œë¦¼ ì „ì†¡.")
                print(f"   - Batch Set Key: {batch_set_key}")

        except redis.exceptions.RedisError as e:
            print(f"âŒ Redisì— ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        except Exception as e:
            print(f"âŒ ì €ì¥ ë¡œì§ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")