# cctv_event_detector/inference/strategies/object_detector.py
import cv2 # ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•´ OpenCVë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
import numpy as np # OpenCVì™€ í•¨ê»˜ ì‚¬ìš©ë  NumPyë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from typing import Dict, Any, List
from ultralytics import YOLO
from collections import Counter

from config import YOLO_OD_MODEL_PATH
from cctv_event_detector.inference.strategies.base import InferenceStrategy
from cctv_event_detector.core.models import CapturedImage

class YOLOObjectDetector(InferenceStrategy):
    """
    YOLO ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ê°ì²´ë¥¼ íƒì§€í•˜ëŠ” ì‹¤ì œ êµ¬í˜„ì²´ì…ë‹ˆë‹¤.
    """
    def __init__(self):
        """
        config íŒŒì¼ë¡œë¶€í„° ëª¨ë¸ ê²½ë¡œë¥¼ ë¡œë“œí•˜ì—¬ YOLO ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        """
        self.model = YOLO(YOLO_OD_MODEL_PATH)
        print(f"âœ… YOLO Object Detection model loaded from: {YOLO_OD_MODEL_PATH}")

    # âœ¨ --- START: YOLO ì¶”ë¡  ì „ìš© ì „ì²˜ë¦¬ ë©”ì„œë“œ ì¶”ê°€ --- âœ¨
    def _preprocess_for_yolo(self, images: List[np.ndarray]) -> List[np.ndarray]:
        """
        ì…ë ¥ëœ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ YOLO ì¶”ë¡ ì— ë§ê²Œ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
        ê°€ì¥ ì¤‘ìš”í•œ ë‹¨ê³„ëŠ” OpenCVì˜ BGR ì±„ë„ì„ ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” RGB ì±„ë„ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
        """
        processed_images = []
        for img in images:
            # CapturedImage.image_dataëŠ” OpenCVë¡œ ìƒì„±ëœ BGR ì´ë¯¸ì§€ì…ë‹ˆë‹¤.
            # YOLO ëª¨ë¸ì€ RGB ì…ë ¥ì„ ê¸°ëŒ€í•˜ë¯€ë¡œ, ì»¬ëŸ¬ ì±„ë„ ìˆœì„œë¥¼ ë³€í™˜í•©ë‹ˆë‹¤.
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            processed_images.append(img_rgb)
        
        # ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŒì„ ë¡œê·¸ë¡œ ë‚¨ê¹ë‹ˆë‹¤.
        if processed_images:
            print(f"INFO: Preprocessed {len(processed_images)} images for YOLO (BGR -> RGB).")
            
        return processed_images
    # âœ¨ --- END: YOLO ì¶”ë¡  ì „ìš© ì „ì²˜ë¦¬ ë©”ì„œë“œ ì¶”ê°€ --- âœ¨

    def run(self, captured_images: List[CapturedImage], inference_results: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì…ë ¥ëœ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•´ YOLO ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•˜ê³ , ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.
        """
        print("Running YOLO Object Detector...")
        
        # 1. ì¶”ë¡ í•  ì›ë³¸ ì´ë¯¸ì§€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        image_data_list = [img.image_data for img in captured_images]
        if not image_data_list:
            return inference_results

        # âœ¨ --- START: í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ --- âœ¨
        # 2. YOLO ëª¨ë¸ì— ì…ë ¥í•˜ê¸° ì „ì— ì „ìš© ì „ì²˜ë¦¬ ë©”ì„œë“œë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
        # processed_image_list = self._preprocess_for_yolo(image_data_list)
        processed_image_list = image_data_list # cvt ì „ì²˜ë¦¬ ì—†ì´ ë°”ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        
        # 3. ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¡œ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        yolo_results = self.model(processed_image_list, verbose=False)
        # âœ¨ --- END: í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ --- âœ¨

        # 4. ì¶”ë¡  ê²°ê³¼ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤. (ì´í›„ ë¡œì§ì€ ë™ì¼)
        for i, capture in enumerate(captured_images):
            image_id = capture.image_id
            if image_id not in inference_results:
                inference_results[image_id] = {}

            result = yolo_results[i]
            detected_objects = []

            for box in result.boxes:
                # ğŸ”´ ì¤‘ìš”: YOLOëŠ” ì¤‘ì‹¬ì  ê¸°ì¤€ ì¢Œí‘œë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ ì¢Œìƒë‹¨ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
                center_x, center_y, width, height = box.xywh[0].tolist()
                
                # ì¢Œìƒë‹¨ ê¸°ì¤€ ì¢Œí‘œë¡œ ë³€í™˜
                x_min = center_x - width / 2
                y_min = center_y - height / 2
                
                # ë°˜ì˜¬ë¦¼í•˜ì—¬ ì •ìˆ˜ë¡œ ë³€í™˜
                bbox_xywh = [round(x_min), round(y_min), round(width), round(height)]
                
                detected_objects.append({
                    "class_id": int(box.cls[0]),
                    "class_name": self.model.names[int(box.cls[0])],
                    "confidence": float(box.conf[0]),
                    "bbox_xywh": bbox_xywh  # ì´ì œ [x_min, y_min, width, height] í˜•ì‹
                })
            
            inference_results[image_id]["detections"] = detected_objects
            
            total_objects = len(detected_objects)
            if total_objects > 0:
                class_counts = Counter(obj['class_name'] for obj in detected_objects)
                class_summary = ", ".join([f"{name} ({count})" for name, count in class_counts.items()])
                print(f"ğŸ” Found {total_objects} objects in '{image_id}': {class_summary}")
            else:
                print(f"ğŸ—‘ï¸ Found 0 objects in '{image_id}'")
            
        return inference_results