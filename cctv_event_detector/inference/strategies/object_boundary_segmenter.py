# cctv_event_detector/inference/strategies/object_boundary_segmenter.py
import torch
import numpy as np
import cv2
from typing import Dict, Any, List

# --- ì„¤ì • ë° ê¸°ë³¸ í´ë˜ìŠ¤ ì„í¬íŠ¸ ---
from config import (
    SAM_CHECKPOINT_PATH,
    SAM_MODEL_TYPE,
    BOUNDARY_TARGET_CLASSES,
    SAM_BOUNDARY_OUTPUT_DIR,
)
from .base import InferenceStrategy
from cctv_event_detector.core.models import CapturedImage

# --- SAM ê´€ë ¨ í´ë˜ìŠ¤ ì„í¬íŠ¸ ---
from segment_anything import sam_model_registry, SamPredictor

class SAMObjectBoundarySegmenter(InferenceStrategy):
    """
    YOLOë¡œ íƒì§€ëœ ê°ì²´ì˜ BBoxë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©í•˜ì—¬ SAMìœ¼ë¡œ ì •í™•í•œ ê²½ê³„ì„ ì„ ì°¾ëŠ” ì „ëµ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    def __init__(self):
        """
        SAM ëª¨ë¸ê³¼ Predictorë¥¼ ì´ˆê¸°í™”í•˜ê³ , configì—ì„œ ì„¤ì •ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
        """
        print("Initializing SAM Object Boundary Segmenter...")
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # SAM ëª¨ë¸ ë¡œë“œ
        sam = sam_model_registry[SAM_MODEL_TYPE](checkpoint=str(SAM_CHECKPOINT_PATH))
        sam.to(device=self.device)
        self.predictor = SamPredictor(sam)
        print(f"âœ… SAM Predictor ('{SAM_MODEL_TYPE}') loaded successfully.")

        # âœ¨ ìš”êµ¬ì‚¬í•­ 2: íƒ€ê²Ÿ í´ë˜ìŠ¤ ì„¤ì •ì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ setìœ¼ë¡œ ì²˜ë¦¬
        self.target_classes = set(BOUNDARY_TARGET_CLASSES) if BOUNDARY_TARGET_CLASSES else set()
        
        if self.target_classes:
            print(f"ğŸ¯ Target classes for boundary finding: {self.target_classes}")
        else:
            print("ğŸ¯ Target classes not specified, processing all classes.")

        self.output_dir = SAM_BOUNDARY_OUTPUT_DIR
        self.output_dir.mkdir(parents=True, exist_ok=True)
        print(f"ğŸ’¾ Boundary visualization output dir: {self.output_dir}")

    def run(self, captured_images: List[CapturedImage], inference_results: Dict[str, Any]) -> Dict[str, Any]:
        print("Running SAM Object Boundary Segmenter...")

        for capture in captured_images:
            image_id = capture.image_id
            original_image = capture.image_data

            detections = inference_results.get(image_id, {}).get("detections", [])
            if not detections:
                continue

            rgb_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
            self.predictor.set_image(rgb_image)

            boundary_masks = []
            vis_image = original_image.copy()

            # ì´ë¯¸ì§€ ë†’ì´ì™€ ë„ˆë¹„ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            # vis_imageëŠ” NumPy ë°°ì—´ì´ë¯€ë¡œ, shape ì†ì„±ì„ í†µí•´ ë†’ì´ì™€ ë„ˆë¹„ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            image_height, image_width = vis_image.shape[:2]
            
            # âœ¨ ìš”êµ¬ì‚¬í•­ 1: ì‹œê°í™” ê°•í™”ë¥¼ ìœ„í•´ ëª¨ë“  YOLO íƒì§€ ê²°ê³¼ë¥¼ ë¨¼ì € ê·¸ë¦¼
            for detection in detections:
                self._draw_yolo_bbox_and_label(vis_image, detection)

            for detection in detections:
                # âœ¨ ìš”êµ¬ì‚¬í•­ 2: íƒ€ê²Ÿ í´ë˜ìŠ¤ê°€ ë¹„ì–´ìˆê±°ë‚˜, í´ë˜ìŠ¤ê°€ íƒ€ê²Ÿì— í¬í•¨ë˜ë©´ ì²˜ë¦¬
                should_process = not self.target_classes or detection['class_name'] in self.target_classes
                
                if should_process:
                    # --- ğŸ”´ START: ì¢Œí‘œ í¬ë§· ìˆ˜ì • ---
                    # object_detectorëŠ” [x_min, y_min, width, height] í¬ë§·ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
                    x_min, y_min, w, h = detection['bbox_xywh']
                    
                    # SAMì€ [x1, y1, x2, y2] ì¦‰ (ì¢Œìƒë‹¨, ìš°í•˜ë‹¨) í¬ë§·ì„ ìš”êµ¬í•©ë‹ˆë‹¤.
                    input_box = np.array([x_min, y_min, x_min + w, y_min + h])
                    # --- ğŸ”´ END: ì¢Œí‘œ í¬ë§· ìˆ˜ì • ---

                    # --- ğŸŸ¢ START: input_box ìƒí•˜ 10% í™•ì¥ ë° ì´ë¯¸ì§€ ê²½ê³„ ì²˜ë¦¬ ---
                    # í˜„ì¬ ë†’ì´ ê³„ì‚°
                    current_height = input_box[3] - input_box[1]
                    # ëŠ˜ë¦´ ë†’ì´ (10%)
                    extend_height = current_height * 0.1

                    # y1ì„ ìœ„ë¡œ 10% í™•ì¥ (ê°ì†Œ)í•˜ë˜, 0ë³´ë‹¤ ì‘ì•„ì§€ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
                    input_box[1] = max(0.0, input_box[1] - extend_height) 
                    # y2ë¥¼ ì•„ë˜ë¡œ 10% í™•ì¥ (ì¦ê°€)í•˜ë˜, ì´ë¯¸ì§€ ë†’ì´-1ì„ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
                    input_box[3] = min(float(image_height - 1), input_box[3] + extend_height)
                    
                    # x1ê³¼ x2ë„ ì´ë¯¸ì§€ ê²½ê³„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ ì œí•œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (í•„ìš”ì‹œ)
                    # input_box[0] = max(0.0, input_box[0])
                    # input_box[2] = min(float(image_width - 1), input_box[2])
                    # --- ğŸŸ¢ END: input_box ìƒí•˜ 10% í™•ì¥ ë° ì´ë¯¸ì§€ ê²½ê³„ ì²˜ë¦¬ ---

                    masks, scores, _ = self.predictor.predict(
                        box=input_box,
                        multimask_output=False
                    )
                    mask = masks[0]
                    
                    boundary_masks.append({
                        "class_name": detection['class_name'],
                        "confidence": scores[0],
                        "segmentation_mask": mask
                    })
                    # SAM ë§ˆìŠ¤í¬ëŠ” ì²˜ë¦¬ëœ ê°ì²´ì— ëŒ€í•´ì„œë§Œ ê·¸ë¦¼
                    self._draw_sam_mask_on_image(vis_image, mask)

            if boundary_masks:
                output_dir_path = self.output_dir / image_id
                output_dir_path.mkdir(parents=True, exist_ok=True)
                output_path = output_dir_path / f"{image_id}_boundaries.jpg"
                cv2.imwrite(str(output_path), vis_image)
                print(f"ğŸ–¼ï¸ Saved boundary visualization to {output_path}")

                if "boundary_masks" not in inference_results[image_id]:
                    inference_results[image_id]['boundary_masks'] = []
                inference_results[image_id]['boundary_masks'].extend(boundary_masks)

        return inference_results

    def _draw_yolo_bbox_and_label(self, image: np.ndarray, detection: Dict[str, Any]):
        """
        ì´ë¯¸ì§€ì— YOLO ë°”ìš´ë”© ë°•ìŠ¤ì™€ í´ë˜ìŠ¤ ë ˆì´ë¸”ì„ ê·¸ë¦½ë‹ˆë‹¤.
        """
        # --- ğŸ”´ START: ì¢Œí‘œ í¬ë§· ìˆ˜ì • ---
        # detection['bbox_xywh']ëŠ” [x_min, y_min, width, height] í¬ë§·ì…ë‹ˆë‹¤.
        x_min, y_min, w, h = map(int, detection['bbox_xywh'])
        class_name = detection['class_name']
        
        # BBox ì¢Œí‘œ ê³„ì‚°
        x1, y1 = x_min, y_min
        x2, y2 = x_min + w, y_min + h
        # --- ğŸ”´ END: ì¢Œí‘œ í¬ë§· ìˆ˜ì • ---
        
        # BBox ê·¸ë¦¬ê¸° (ì´ˆë¡ìƒ‰)
        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        
        # í´ë˜ìŠ¤ëª… í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        label = f"{class_name}"
        (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
        
        # í…ìŠ¤íŠ¸ ë°°ê²½ ë° í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        cv2.rectangle(image, (x1, y1 - 20), (x1 + label_w, y1), (0, 255, 0), -1)
        cv2.putText(image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)

    def _draw_sam_mask_on_image(self, image: np.ndarray, mask: np.ndarray):
        """
        ì£¼ì–´ì§„ ì´ë¯¸ì§€ì— SAM ë§ˆìŠ¤í¬ë¥¼ ëœë¤ ìƒ‰ìƒìœ¼ë¡œ ì˜¤ë²„ë ˆì´í•©ë‹ˆë‹¤.
        """
        color = np.random.randint(0, 255, 3, dtype=np.uint8)
        overlay = image.copy()
        overlay[mask] = color
        cv2.addWeighted(overlay, 0.5, image, 0.5, 0, image)